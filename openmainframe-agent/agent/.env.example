# LLM Provider — Anthropic API key (default provider)
ANTHROPIC_API_KEY=sk-ant-...

# LLM Configuration
# LLM_PROVIDER=anthropic          # anthropic | litellm-proxy | openai
# LLM_MODEL=claude-sonnet-4-5-20250929

# ── OpenAI-compatible proxy (LiteLLM, LMStudio, etc.) ──
# Proxy must support the Anthropic Messages API format (/v1/messages)
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-5-mini
# OPENAI_BASE_URL=http://localhost:4141/v1
# OPENAI_API_KEY=dummy

# ── LiteLLM Proxy (recommended for production) ──
# Start proxy: litellm --config litellm-config.yaml
# LLM_PROVIDER=litellm-proxy
# LLM_MODEL=claude-sonnet
# LITELLM_PROXY_URL=http://localhost:4000
# LITELLM_API_KEY=sk-1234

# OpenMainframe binary path (relative to repo root or absolute)
OPEN_MAINFRAME_BIN=../../target/release/open-mainframe

# Workspace root (restricts file access to this directory)
WORKSPACE_ROOT=../../

# Server port
PORT=8123
